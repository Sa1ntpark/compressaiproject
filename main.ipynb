{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351c698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# data split, model choise, GPU setting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from compressai.zoo import cheng2020_attn\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# data 읽어오기\n",
    "data1024_filename = 'data1024lst.txt'\n",
    "\n",
    "f = open(data1024_filename,'r')\n",
    "data1024copy = [line.strip() for line in f.readlines()]\n",
    "print(len(data1024copy))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# train:val:test = 7:1:2\n",
    "X_train, X_test = train_test_split(data1024copy, test_size=0.2, random_state=42)\n",
    "X_train, X_val = train_test_split(X_train, test_size =1/8, random_state=42)\n",
    "\n",
    "PATH = \"/nas/userdata/kim_y/CME autodetection/LZ/CME_unpiped/\"\n",
    "MAX_INT16 = 32767\n",
    "\n",
    "# GPU 사용\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "# quality=6 → 논문에서 사용한 lambda=0.0483에 해당\n",
    "model = cheng2020_attn(pretrained=True, quality=6).train().to(device)\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5399da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "# <전제>\n",
    "# 논문에서의 전처리는 16bit정수형 -> 8bit정수형 byte scale\n",
    "# 모델도 8bit정수형으로 양자화 되어야 하는가? 해석의 모호함 존재\n",
    "# -> 우선 전처리에서 byte scale은 빼고 진행\n",
    "from torchvision import transforms\n",
    "from compressai.losses import RateDistortionLoss\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "\n",
    "log_max = 0\n",
    "log_min = 0\n",
    "\n",
    "def cut_saturation(img_arr, threshold=3):\n",
    "    pixels = img_arr.flatten()\n",
    "    pmean = np.mean(pixels)\n",
    "    pstd = np.std(pixels)  \n",
    "    pmax = threshold*pstd + pmean \n",
    "    modified_array = np.where(img_arr > pmax, pmax, img_arr)\n",
    "    return modified_array\n",
    "\n",
    "def minmax(img_arr):\n",
    "    global log_max\n",
    "    global log_min \n",
    "    log_max = torch.max(img_arr)\n",
    "    log_min = torch.min(img_arr)\n",
    "    byteimage = ((img_arr - log_min) / (log_max - log_min))\n",
    "    return byteimage\n",
    "\n",
    "def rescale(img_arr):\n",
    "    global log_max\n",
    "    global log_min \n",
    "    rescaled_img = img_arr * (log_max - log_min) + log_min\n",
    "    return rescaled_img\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # ValueError: given numpy array has byte order different from the native byte order. \n",
    "    # Conversion between byte orders is currently not supported.\n",
    "    # 위의 에러 해결 위해 numpy int16을 float32로 바꿔주는 코드 추가\n",
    "    lambda img: img.astype(np.float32), # byte\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((512,512)), \n",
    "    # log conversion\n",
    "    lambda img: torch.log1p(img), # [log_min, log_max]\n",
    "    minmax, # [0,1] \n",
    "    lambda img: torch.Tensor.repeat(img,3,1,1).type(torch.float).to(device)\n",
    "])\n",
    "\n",
    "invtransform = transforms.Compose([\n",
    "    lambda img: img.squeeze(0).permute(1, 2, 0),\n",
    "    # numpy로 바꾸기 전에 max값으로 나누고 mean때리고 exmp1하는게 더 빠르지 않을까\n",
    "    lambda img: img.mean(axis=2),\n",
    "    # inverse byte scale\n",
    "    lambda img: img/torch.max(img), # [0,1]\n",
    "    rescale, # [log_min, log_max]\n",
    "    # invers log conversion\n",
    "    lambda img: torch.expm1(img)# [0, max]\n",
    "])\n",
    "\n",
    "# 사용자 정의 Dataset 클래스 생성\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_name_lst, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = data_name_lst \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[idx])\n",
    "        image = fits.open(img_path)[0].data\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "    \n",
    "\n",
    "# variable setting\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "patience = 15 # max patience\n",
    "j = 0 # current patience\n",
    "epoch = 0 \n",
    "criterion = RateDistortionLoss(lmbda=0.0483)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "num_workers = 0\n",
    "\n",
    "# dataset\n",
    "image_trainset = ImageDataset(PATH, X_train,transform=transform)\n",
    "train_loader = DataLoader(image_trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "image_valset = ImageDataset(PATH, X_val,transform=transform)\n",
    "val_loader = DataLoader(image_valset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "image_testset = ImageDataset(PATH, X_test,transform=transform)\n",
    "test_loader = DataLoader(image_testset, shuffle=False)\n",
    "\n",
    "train_loss_lst = []\n",
    "val_loss_lst = []\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 학습 모드로 설정\n",
    "    train_loss = 0.0\n",
    "    for i, inputs in enumerate(train_loader):\n",
    "        # 순전파 (Forward pass)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        # 역전파 및 파라미터 업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss['loss'].backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss['loss'] * inputs.size(0)\n",
    "        if i%10 == 0:\n",
    "            print(\"epoch\",epoch+1,\"/ iteration:\",i,\", ratio:\",i*batch_size/len(train_loader)*100,\"%\")\n",
    "    train_loss /= len(X_train)\n",
    "    train_loss_lst.append(train_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}')\n",
    "\n",
    "    # 검증 루프\n",
    "    model.eval()  # 평가 모드로 설정\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs_val in val_loader:\n",
    "            outputs_val = model(inputs_val)\n",
    "            loss_val = criterion(outputs_val, inputs_val)\n",
    "            val_loss += loss_val['loss'] * inputs_val.size(0)\n",
    "        val_loss /= len(X_val)\n",
    "        val_loss_lst.append(val_loss)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Early Stopping 체크\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            j = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth') # Best 모델 저장\n",
    "        else:\n",
    "            j += 1\n",
    "            if j >= patience:\n",
    "                print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
